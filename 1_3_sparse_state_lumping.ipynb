{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse state networks \n",
    "Second-order dynamics on a physical network can be described by first-order dynamics on a second-order state network.\n",
    "\n",
    "We can represent this second-order network by it's _state transition matrix_ $P_{ij}$ with the probabilities for the random walker to transition from state node $i$ to state node $j$.\n",
    "\n",
    "In this view, we may note that some rows have similar probability distributions. We can measure how much information we lose when merging two state nodes with the [Jensen-Shannon Distance](https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence).\n",
    "\n",
    "The idea behind sparse state networks is that we can lump state nodes (within each physical node) that constrain the network flow in a similar way without losing (much) information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms to a general machine learning problem\n",
    "We will here solve the problem using standard [clustering algorithms](http://scikit-learn.org/stable/modules/clustering.html#clustering) from the [scikit-learn](http://scikit-learn.org/) package.\n",
    "\n",
    "In order to do that, we have to transform the state network into features usable for machine learning. We can do this with the help of the code in [state_lumping_network.py](./state_lumping_network.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from state_lumping_network import StateNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read state network from file 'data/toy_states.net'...\n",
      " -> StateNetwork (5 physical nodes, 12 state nodes and 32 links)\n"
     ]
    }
   ],
   "source": [
    "net = StateNetwork()\n",
    "net.readFromFile(\"data/toy_states.net\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![toy_states](figures/toy_states_full.png)\n",
    "\n",
    "Figure 1: Second-order state network in `data/toy_states.net`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature matrix\n",
    "\n",
    "The feature matrix for a physical node is simply the rows of the state transition matrix for the state nodes belonging to that physical node.\n",
    "To simplify, there is a `getFeatureMatrix` method that removes all all-zero rows and columns in the feature matrix and provides a mapping back to the original state network. It takes the physical node id as input parameter and returns a tuple `(X, T)`, where `X` is the feature matrix (np.array) of size (numNonDanglingStateNodes, numLinkedNodes) and `T` is a dictionary transforming row index in the feature matrix to state node id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix for the central physical node: \n",
      "[[0.4 0.4 0.1 0.1]\n",
      " [0.4 0.4 0.1 0.1]\n",
      " [0.1 0.1 0.4 0.4]\n",
      " [0.1 0.1 0.4 0.4]]\n",
      " rowToStateId: {0: 1, 1: 2, 2: 7, 3: 8}\n"
     ]
    }
   ],
   "source": [
    "X, rowToStateId = net.getFeatureMatrix(1)\n",
    "print(\"Feature matrix for the central physical node: \\n{}\\n rowToStateId: {}\".format(X, rowToStateId))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure pairwise similarity\n",
    "Now we can compare rows pairwise and cluster the most similar rows together. The Jensen-Shannon distance is unfortunately not implemented in scikit-learn (though it exist in a [pull request](https://github.com/scikit-learn/scikit-learn/pull/4191)), so let's create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.5273252365595998\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "def plogp(x):\n",
    "    x = np.asarray(x)\n",
    "    return x * np.log2(x, where = x>0)\n",
    "\n",
    "def entropy(x):\n",
    "    return -np.sum(plogp(x))\n",
    "\n",
    "def jensen_shannon_distance(x1, x2):\n",
    "    x1 = np.asarray(x1)\n",
    "    x2 = np.asarray(x2)\n",
    "    mix = (x1 + x2) / 2\n",
    "    return np.sqrt(entropy(mix) - (entropy(x1) + entropy(x2)) / 2)\n",
    "\n",
    "def jensen_shannon_distances(X):\n",
    "    return pairwise_distances(X, metric=jensen_shannon_distance)\n",
    "\n",
    "print(jensen_shannon_distance(X[0], X[1]))\n",
    "print(jensen_shannon_distance(X[1], X[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster with scikit-learn\n",
    "\n",
    "Now we can use general [scikit-learn clustering algorithm](http://scikit-learn.org/stable/modules/clustering.html) that takes a custom pairwise distance function as a metric, like [Agglomerative Clustering](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering). We can also use for example `cosine` instead with similar result. Many take as input the number of clusters you want. For the example feature matrix, it's two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster labels in feature matrix space: [1 1 0 0]\n",
      "Cluster labels in state node space: {1: 1, 2: 1, 7: 0, 8: 0}\n"
     ]
    }
   ],
   "source": [
    "model = cluster.AgglomerativeClustering(\n",
    "    linkage=\"complete\",\n",
    "    affinity=jensen_shannon_distances,\n",
    "#     affinity=\"cosine\",\n",
    "    n_clusters=2\n",
    ")\n",
    "\n",
    "labels = model.fit_predict(X)\n",
    "print(\"Cluster labels in feature matrix space: {}\\nCluster labels in state node space: {}\".format(\n",
    "    labels,\n",
    "    {rowToStateId[i]:clusterId for i,clusterId in enumerate(labels)}\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lump whole network\n",
    "Now we are ready to run this on the whole network. For convenience, `StateNetwork` provides a method `clusterStateNodes` that takes an argument `clusterFeatureMatrix` where you can send in a custom clustering function. This function gets a feature matrix as input argument and expects an array of cluster labels back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster state nodes...\n",
      "Generate lumped state network from clustering...\n",
      " -> 6 state nodes and 16 links in lumped network.\n"
     ]
    }
   ],
   "source": [
    "def getFeatureClusterFunction(clusterRate=0.5):\n",
    "    def calcClusters(X):\n",
    "        numStates, numFeatures = X.shape\n",
    "        if numStates < 2 or numFeatures < 2:\n",
    "            # Don't cluster if too small\n",
    "            return list(range(numStates))\n",
    "\n",
    "        # Can be an adaptive number of clusters based on entropy reduction\n",
    "        n_clusters = max(1, int(clusterRate * numStates))\n",
    "        model = cluster.AgglomerativeClustering(\n",
    "            linkage=\"complete\",\n",
    "            affinity=jensen_shannon_distances,\n",
    "#             affinity=\"cosine\",\n",
    "            n_clusters=n_clusters\n",
    "        )\n",
    "\n",
    "        labels = model.fit_predict(X)\n",
    "        return labels\n",
    "    return calcClusters\n",
    "\n",
    "net.clusterStateNodes(clusterFeatureMatrix=getFeatureClusterFunction())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Did we lose any information?\n",
    "The state network has two methods `calcEntropyRate()` and `calcLumpedEntropyRate()` to calculate the average number of bits required to encode the random walk on each physical node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy rate before: 1.2406426982957872, after: 1.2406426982957874\n"
     ]
    }
   ],
   "source": [
    "h1 = net.calcEntropyRate()\n",
    "h2 = net.calcLumpedEntropyRate()\n",
    "print(\"Entropy rate before: {}, after: {}\".format(h1, h2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing lumped state network to file 'output/toy_lumped.net'...\n",
      "# physical nodes: 5\n",
      "# state nodes: 12\n",
      "# lumped state nodes: 6\n",
      "*Vertices\n",
      "1 \"1\"\n",
      "2 \"2\"\n",
      "3 \"3\"\n",
      "4 \"4\"\n",
      "5 \"5\"\n",
      "*States\n",
      "#lumpedStateId physicalId lumpedStateIds\n",
      "1 1 \"[7, 8]\"\n",
      "2 1 \"[1, 2]\"\n",
      "3 2 \"[3, 4]\"\n",
      "4 3 \"[5, 6]\"\n",
      "5 4 \"[9, 10]\"\n",
      "6 5 \"[11, 12]\"\n",
      "*Links\n",
      "1 5 1.6\n",
      "1 6 1.6\n",
      "1 3 0.4\n",
      "1 4 0.4\n",
      "2 3 1.6\n",
      "2 4 1.6\n",
      "2 5 0.4\n",
      "2 6 0.4\n",
      "3 2 2.0\n",
      "3 4 2.0\n",
      "4 2 2.0\n",
      "4 3 2.0\n",
      "5 1 2.0\n",
      "5 6 2.0\n",
      "6 1 2.0\n",
      "6 5 2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "net.writeLumpedStateNetwork(\"output/toy_lumped.net\")\n",
    "print(Path('output/toy_lumped.net').read_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have generated the sparse network (with lossless compression)\n",
    "![toy_states](figures/toy_states_full.png)\n",
    "![toy_states](figures/toy_states_sparse.png)\n",
    "\n",
    "To the left, the original second-order network. To the right, the sparse network formed by lumping similar state nodes within each physical node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
