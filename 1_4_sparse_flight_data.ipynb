{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sparse flight data\n",
    "\n",
    "A key question for the generation of sparse state networks is _how_ sparse. If we lump all state nodes with each physical node, we lose all higher-order information and may underfit. On the other hand, keeping all second-order state nodes may overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In this tutorial, we will generate second-order state networks from path data, then from them generate multiple sparse networks with different number of (lumped) state nodes, and finally evaluate the result with Infomap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Generate training and validation sets\n",
    "To get a bigger network, we can merge the flight path data from the four quarters (`\"data/air2015_{q}_paths.net\" for q in [1,2,3,4]`). To evaluate the goodness of fit, we can split each path randomly in either a _training_ or a _validation_ set and write a path data file for each of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def getTrainingValidationPath(row, splitWeight=True):\n",
    "    if not splitWeight:\n",
    "        return (row, None) if np.random.random() < 0.5 else (None, row)\n",
    "    path = row.split()\n",
    "    weight = int(path[-1])\n",
    "    path = ' '.join(path[:-1])\n",
    "    trainingWeight = np.random.binomial(weight, 0.5)\n",
    "    validationWeight = weight - trainingWeight\n",
    "    trainingPath = \"{} {}\\n\".format(path, trainingWeight) if trainingWeight > 0 else None\n",
    "    validationPath = \"{} {}\\n\".format(path, validationWeight) if validationWeight > 0 else None\n",
    "    if trainingPath is None or validationPath is None:\n",
    "        return None, None\n",
    "    return trainingPath, validationPath\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def generateData(inputFilenames):\n",
    "    \"\"\"Merge path data from inputFilenames and write to two path data files\n",
    "    for training and validation. Each path in the input data is selected by\n",
    "    random to be written to either the training or validation data file\"\"\"\n",
    "    data = { 'training': [], 'validation': [] }\n",
    "    # Read path data\n",
    "    for filename in inputFilenames:\n",
    "        print(\"Parsing paths from '{}'...\".format(filename))\n",
    "        with open(filename, mode='r') as infile:\n",
    "            isPath = False\n",
    "            for row in infile:\n",
    "                if not isPath and row[:6] == \"*paths\":\n",
    "                    isPath = True\n",
    "                    continue\n",
    "                if not isPath:\n",
    "                    continue\n",
    "                trainingPath, validationPath = getTrainingValidationPath(row)\n",
    "                if trainingPath is not None:\n",
    "                    data['validation'].append(trainingPath)\n",
    "                if validationPath is not None:\n",
    "                    data['training'].append(validationPath)\n",
    "    # Write path data\n",
    "    for name, paths in data.items():\n",
    "        outFilename = \"output/paths_{}.net\".format(name)\n",
    "        print(\"-> Writing {} paths to {}...\".format(len(paths), outFilename))\n",
    "        with open(outFilename, mode='w') as outfile:\n",
    "            outfile.write(\"*paths\\n\")\n",
    "            for p in paths:\n",
    "                outfile.write(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "inputFilenames = [\"data/air2015_{}_paths.net\".format(quarter) for quarter in [1,2,3,4]]\n",
    "generateData(inputFilenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Generate state networks from paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import infomap\n",
    "def generateStateNetworkFromPaths(inputFilename, outputFilename, markovOrder):\n",
    "    network = infomap.Network(\"--directed --path-markov-order {}\".format(markovOrder))\n",
    "    print(\"Reading {}...\".format(inputFilename))\n",
    "    network.readInputData(inputFilename)\n",
    "    print(\"Writing {}...\".format(outputFilename))\n",
    "    network.writeStateNetwork(outputFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "generateStateNetworkFromPaths(\"output/paths_training.net\", \"output/states_training_order_2.net\", 2)\n",
    "generateStateNetworkFromPaths(\"output/paths_validation.net\", \"output/states_validation_order_2.net\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generate _sparse_ state networks\n",
    "\n",
    "Here we will generate multiple lumped state networks with different amount of state nodes. A simple way is to parameterise this with a cluster rate $r$ going from 0.1 to 1, where `n_clusters = max(1, int(r * numStateNodes)`. For convenience, you can just send in the argument `clusterRate` to `clusterStateNodes` to achieve this, instead of the cluster function in the previous tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from state_lumping_network import StateNetwork\n",
    "\n",
    "sparseNet = StateNetwork()\n",
    "sparseNet.readFromFile(\"output/states_training_order_2.net\")\n",
    "\n",
    "h0 = sparseNet.calcEntropyRate()\n",
    "print(\"\\nOriginal average entropy rate:\", h0)\n",
    "print(\"Original number of state nodes:\", sparseNet.numStateNodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "clusterRates = np.linspace(0.1, 1, 10)\n",
    "numStates = []\n",
    "entropyRate = []\n",
    "\n",
    "for i, clusterRate in enumerate(clusterRates):\n",
    "    sparseNet.clusterStateNodes(clusterRate=clusterRate)\n",
    "    s = sparseNet.numLumpedStateNodes()\n",
    "    h = sparseNet.calcLumpedEntropyRate()\n",
    "    sparseNet.writeLumpedStateNetwork(\"output/states_training_lumped_{}.net\".format(i))\n",
    "    numStates.append(s)\n",
    "    entropyRate.append(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### How much information do we lose as we reduce the number of state nodes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(numStates, entropyRate, marker='o')\n",
    "plt.xlabel(\"number of lumped states\")\n",
    "plt.ylabel(\"entropy rate\")\n",
    "plt.axhline(y=h0, color='r', linestyle='-')\n",
    "# plt.axvline(x=sparseNet.numStateNodes(), color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Note that the original number of state nodes can be much larger than the maximum in the lumped state networks due to dangling nodes, which are lumped implicitly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Validate with Infomap\n",
    "The goal here is to calculate the codelength for the validation network, given the different partitions found on the lumped training networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "trainingCodelengths = []\n",
    "validationCodelengths = []\n",
    "\n",
    "def calcCodelength(inputFilename, cluInputFile, flags=\"--directed --two-level\"):\n",
    "    im = infomap.Infomap(\"{} --no-infomap --input {} --cluster-data {}\".format(flags, inputFilename, cluInputFile))\n",
    "    im.run()\n",
    "    return im.codelength()\n",
    "\n",
    "def partition(inputFilename, cluOutputFile=None, flags=\"--directed --two-level\"):\n",
    "    im = infomap.Infomap(flags)\n",
    "    im.network().readInputData(inputFilename)\n",
    "    im.run()\n",
    "    if cluOutputFile:\n",
    "        # Use second argument True to write the state-level clustering\n",
    "        im.writeClu(cluOutputFile, True) # Second parameter shows States\n",
    "    return im.codelength()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "for i, clusterRate in enumerate(clusterRates):\n",
    "    trainingCodelength = partition(\"output/states_training_lumped_{}.net\".format(i),\n",
    "             \"output/states_training_lumped_{}.clu\".format(i))\n",
    "    validationCodelength = calcCodelength(\"output/states_validation_order_2.net\",\n",
    "             \"output/states_training_lumped_{}.clu\".format(i))\n",
    "    trainingCodelengths.append(trainingCodelength)\n",
    "    validationCodelengths.append(validationCodelength)\n",
    "    print(\"{}: training codelength: {}, validation codelength: {}\".format(i, trainingCodelength, validationCodelength))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(numStates, trainingCodelengths, marker='o')\n",
    "plt.plot(numStates, validationCodelengths, marker='x')\n",
    "plt.legend([\"training\", \"validation\"])\n",
    "plt.xlabel(\"number of lumped states\")\n",
    "plt.ylabel(\"codelength\")\n",
    "plt.ylim(ymin=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
